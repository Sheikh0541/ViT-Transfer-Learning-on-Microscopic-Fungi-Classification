{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","machine_shape":"hm","authorship_tag":"ABX9TyO+YVbYF9o1guX8LZ3Pzcmm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import tensorflow as tf\n","import os\n","import numpy as np\n","import random\n","from tqdm.auto import tqdm\n","from skimage.io import imread, imshow\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","from glob import glob\n","import cv2\n","from skimage.io import imread, imshow, show\n","\n","from tensorflow import keras\n","from keras import layers\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","\n","seed = 42\n","np.random.seed = seed  # To get same random seed everytime we run the whole thing.\n","tf.random.set_seed(42)\n","random.seed(seed)"],"metadata":{"id":"5XWxy7AZ6h6_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3s5dJy97NWJ","executionInfo":{"status":"ok","timestamp":1694516830849,"user_tz":-360,"elapsed":24755,"user":{"displayName":"Sheikh Iftekhar Ahmed","userId":"05190100816646482527"}},"outputId":"9a639412-44bd-499a-e714-078c5865a461"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Importing The Dataset Paths"],"metadata":{"id":"Dn1Ul-1G6iJe"}},{"cell_type":"code","source":["print(len(os.listdir(\"/content/drive/MyDrive/ICCIT 2023/Selected_data/H1\")))\n","print(len(os.listdir(\"/content/drive/MyDrive/ICCIT 2023/Selected_data/H2\")))\n","print(len(os.listdir(\"/content/drive/MyDrive/ICCIT 2023/Selected_data/H3\")))\n","print(len(os.listdir(\"/content/drive/MyDrive/ICCIT 2023/Selected_data/H5\")))\n","print(len(os.listdir(\"/content/drive/MyDrive/ICCIT 2023/Selected_data/H6\")))"],"metadata":{"id":"A6024j2d7_bA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694516852377,"user_tz":-360,"elapsed":9775,"user":{"displayName":"Sheikh Iftekhar Ahmed","userId":"05190100816646482527"}},"outputId":"f1a22958-c2f8-46b4-bac2-0e4925026c62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["700\n","700\n","700\n","700\n","700\n"]}]},{"cell_type":"code","source":["!pip install --root-user-action=ignore split-folders"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOTUWMr-9Ffy","executionInfo":{"status":"ok","timestamp":1694516861472,"user_tz":-360,"elapsed":5240,"user":{"displayName":"Sheikh Iftekhar Ahmed","userId":"05190100816646482527"}},"outputId":"b1b1b616-efee-46da-cb30-006fc942d0d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting split-folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n"]}]},{"cell_type":"code","source":["# Only one time run cell\n","import splitfolders\n","\n","input_folder = \"/content/drive/MyDrive/ICCIT 2023/Selected_data\"\n","output = \"/content/split_data/\"\n","\n","splitfolders.ratio(input_folder, output=output, seed=42, ratio=(0.90, 0.10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kdW_jDzG9Ita","executionInfo":{"status":"ok","timestamp":1694516909752,"user_tz":-360,"elapsed":45436,"user":{"displayName":"Sheikh Iftekhar Ahmed","userId":"05190100816646482527"}},"outputId":"ba2adcd4-f82c-4dcc-f7c3-a8a8495d0c7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Copying files: 3500 files [00:45, 77.46 files/s] \n"]}]},{"cell_type":"markdown","source":["## Model Creation"],"metadata":{"id":"J-wg4Vol9phB"}},{"cell_type":"code","source":["learning_rate = 0.001\n","weight_decay = 0.0001\n","batch_size = 64\n","num_epochs = 100\n","image_size = 72  # We'll resize input images to this size\n","patch_size = 6  # Size of the patches to be extract from the input images\n","num_patches = (image_size // patch_size) ** 2\n","projection_dim = 64\n","num_heads = 4\n","transformer_units = [\n","    projection_dim * 2,\n","    projection_dim,\n","]  # Size of the transformer layers\n","transformer_layers = 4\n","mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"],"metadata":{"id":"a7qu7DHPn6D9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Augmentation"],"metadata":{"id":"5_nhg9kIn7ju"}},{"cell_type":"code","source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        layers.Resizing(image_size, image_size),\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(factor=0.02),\n","        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n","    ],\n","    name=\"data_augmentation\",\n",")\n","\n","# Compute the mean and the variance of the training data for normalization.\n","# data_augmentation.layers[0].adapt(x_train)"],"metadata":{"id":"_F5ZTM7sn_Tz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MLP Layer"],"metadata":{"id":"NdrFdINIoNvs"}},{"cell_type":"code","source":["def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n","        x = layers.Dropout(dropout_rate)(x)\n","    return x"],"metadata":{"id":"xnrPHLFsoQva"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Patch Creation as a layer"],"metadata":{"id":"dVZ13hQNoUIa"}},{"cell_type":"code","source":["class Patches(layers.Layer):\n","    def __init__(self, patch_size):\n","        super().__init__()\n","        self.patch_size = patch_size\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patch_dims = patches.shape[-1]\n","        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n","        return patches"],"metadata":{"id":"TNb2iz_YoXDV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Implementing the Patch Encoding Layer"],"metadata":{"id":"sa4s61KXoblA"}},{"cell_type":"code","source":["class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super().__init__()\n","        self.num_patches = num_patches\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded"],"metadata":{"id":"jg55RYtrohRR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ViT Model"],"metadata":{"id":"K8sR6lTCojeo"}},{"cell_type":"code","source":["def create_vit_classifier(layer):\n","\n","    input_shape = (256, 256, 3)\n","    num_classes = 5\n","\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    augmented = layer(inputs)\n","    # Create patches.\n","    patches = Patches(patch_size)(augmented)\n","    # Encode patches.\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","    # Create multiple layers of the Transformer block.\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # Create a multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    # Create a [batch_size, projection_dim] tensor.\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","    # Classify outputs.\n","    logits = layers.Dense(num_classes)(features)\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=logits)\n","\n","    return model\n","\n","model = create_vit_classifier(data_augmentation)\n","model.summary()\n"],"metadata":{"id":"nddu8F9Voohe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run, Train, Test"],"metadata":{"id":"Kqp06K0Ho3xu"}},{"cell_type":"code","source":["# from sklearn.model_selection import StratifiedKFold\n","# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","fold_no = 1\n","acc_per_fold = []\n","history_all = []\n","\n","for k in range(3):\n","\n","    print('   ')\n","    print(f'Training for fold {fold_no} ...', '\\n')\n","    tf.random.set_seed(42+k)\n","\n","    data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                   horizontal_flip=True,\n","                                   vertical_flip=True)\n","\n","    data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","    train_generator = data_generator_with_aug.flow_from_directory(\n","                        '/content/split_data/train',\n","                        target_size=(256, 256),\n","                        batch_size=batch_size,\n","                        class_mode='categorical',\n","                        shuffle=True)\n","\n","    validation_generator = data_generator_no_aug.flow_from_directory(\n","                        '/content/split_data/val',\n","                        target_size=(256, 256),\n","                        batch_size=batch_size,\n","                        class_mode='categorical',\n","                        shuffle=True)\n","\n","\n","\n","\n","    data_augmentation = keras.Sequential([\n","                    layers.Normalization(),\n","                    layers.Resizing(image_size, image_size),\n","                    # layers.RandomFlip(\"horizontal\"),\n","                    layers.RandomRotation(factor=0.02),\n","                    layers.RandomZoom(height_factor=0.1, width_factor=0.1)],\n","                                         name=\"data_augmentation\")\n","\n","\n","    model = create_vit_classifier(data_augmentation)\n","\n","    # optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate,\n","    #                                  weight_decay=weight_decay)\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","                  metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")])\n","\n","    history = model.fit(\n","        train_generator,\n","        epochs=num_epochs,\n","        validation_data = validation_generator,\n","        verbose = 1)\n","\n","    result = model.evaluate(validation_generator)\n","    print(f\"Test accuracy: {round(result[1] * 100, 2)}%\", '\\n')\n","\n","    acc_per_fold.append(result[1]*100)\n","    history_all.append(history)\n","\n","    fold_no = fold_no + 1\n"],"metadata":{"id":"CKHWvGR_o6OI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694520107088,"user_tz":-360,"elapsed":3095565,"user":{"displayName":"Sheikh Iftekhar Ahmed","userId":"05190100816646482527"}},"outputId":"ba717c6e-7737-4a01-bdf9-dd291199cd35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   \n","Training for fold 1 ... \n","\n","Found 3150 images belonging to 5 classes.\n","Found 350 images belonging to 5 classes.\n","Epoch 1/100\n","50/50 [==============================] - 32s 214ms/step - loss: 4.8430 - accuracy: 0.3502 - val_loss: 1.5855 - val_accuracy: 0.4571\n","Epoch 2/100\n","50/50 [==============================] - 10s 198ms/step - loss: 1.6302 - accuracy: 0.3879 - val_loss: 1.3170 - val_accuracy: 0.5000\n","Epoch 3/100\n","50/50 [==============================] - 10s 198ms/step - loss: 1.4144 - accuracy: 0.4321 - val_loss: 1.1898 - val_accuracy: 0.5143\n","Epoch 4/100\n","50/50 [==============================] - 10s 198ms/step - loss: 1.3323 - accuracy: 0.4470 - val_loss: 1.1898 - val_accuracy: 0.4686\n","Epoch 5/100\n","50/50 [==============================] - 10s 200ms/step - loss: 1.2585 - accuracy: 0.4644 - val_loss: 1.1162 - val_accuracy: 0.5086\n","Epoch 6/100\n","50/50 [==============================] - 10s 199ms/step - loss: 1.2144 - accuracy: 0.4990 - val_loss: 1.0523 - val_accuracy: 0.5714\n","Epoch 7/100\n","50/50 [==============================] - 10s 203ms/step - loss: 1.0911 - accuracy: 0.5441 - val_loss: 0.9748 - val_accuracy: 0.5800\n","Epoch 8/100\n","50/50 [==============================] - 10s 199ms/step - loss: 1.0063 - accuracy: 0.5800 - val_loss: 0.8760 - val_accuracy: 0.6314\n","Epoch 9/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.9613 - accuracy: 0.6013 - val_loss: 0.9231 - val_accuracy: 0.6114\n","Epoch 10/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.9335 - accuracy: 0.6086 - val_loss: 0.8494 - val_accuracy: 0.6343\n","Epoch 11/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.9101 - accuracy: 0.6244 - val_loss: 0.8469 - val_accuracy: 0.6314\n","Epoch 12/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.8788 - accuracy: 0.6270 - val_loss: 0.8245 - val_accuracy: 0.6914\n","Epoch 13/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.8320 - accuracy: 0.6438 - val_loss: 0.8093 - val_accuracy: 0.6629\n","Epoch 14/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.8315 - accuracy: 0.6546 - val_loss: 0.8665 - val_accuracy: 0.6171\n","Epoch 15/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.8400 - accuracy: 0.6422 - val_loss: 0.8215 - val_accuracy: 0.6457\n","Epoch 16/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.7769 - accuracy: 0.6762 - val_loss: 0.8138 - val_accuracy: 0.6600\n","Epoch 17/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.7863 - accuracy: 0.6714 - val_loss: 0.7818 - val_accuracy: 0.6771\n","Epoch 18/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.7940 - accuracy: 0.6622 - val_loss: 0.7839 - val_accuracy: 0.6886\n","Epoch 19/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.7916 - accuracy: 0.6756 - val_loss: 0.7577 - val_accuracy: 0.6657\n","Epoch 20/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.7850 - accuracy: 0.6819 - val_loss: 0.8159 - val_accuracy: 0.6771\n","Epoch 21/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.7599 - accuracy: 0.6816 - val_loss: 0.7475 - val_accuracy: 0.6771\n","Epoch 22/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.7735 - accuracy: 0.6825 - val_loss: 0.8296 - val_accuracy: 0.6200\n","Epoch 23/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.7461 - accuracy: 0.6924 - val_loss: 0.7127 - val_accuracy: 0.6686\n","Epoch 24/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.7237 - accuracy: 0.6895 - val_loss: 0.7508 - val_accuracy: 0.6571\n","Epoch 25/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.7308 - accuracy: 0.6987 - val_loss: 0.7869 - val_accuracy: 0.6743\n","Epoch 26/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.7392 - accuracy: 0.7016 - val_loss: 0.7498 - val_accuracy: 0.6514\n","Epoch 27/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.7123 - accuracy: 0.6962 - val_loss: 0.8044 - val_accuracy: 0.6514\n","Epoch 28/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.7266 - accuracy: 0.7029 - val_loss: 0.7583 - val_accuracy: 0.6743\n","Epoch 29/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6897 - accuracy: 0.7089 - val_loss: 0.7243 - val_accuracy: 0.6600\n","Epoch 30/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6627 - accuracy: 0.7229 - val_loss: 0.7775 - val_accuracy: 0.6914\n","Epoch 31/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.6986 - accuracy: 0.7057 - val_loss: 0.7699 - val_accuracy: 0.6686\n","Epoch 32/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6789 - accuracy: 0.7156 - val_loss: 0.8433 - val_accuracy: 0.6629\n","Epoch 33/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.6991 - accuracy: 0.7051 - val_loss: 0.7371 - val_accuracy: 0.6800\n","Epoch 34/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6907 - accuracy: 0.7089 - val_loss: 0.6923 - val_accuracy: 0.6829\n","Epoch 35/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6520 - accuracy: 0.7171 - val_loss: 0.7565 - val_accuracy: 0.6714\n","Epoch 36/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6616 - accuracy: 0.7152 - val_loss: 0.7205 - val_accuracy: 0.6914\n","Epoch 37/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6639 - accuracy: 0.7121 - val_loss: 0.7270 - val_accuracy: 0.6886\n","Epoch 38/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.6637 - accuracy: 0.7263 - val_loss: 0.7881 - val_accuracy: 0.6400\n","Epoch 39/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6765 - accuracy: 0.7117 - val_loss: 0.8144 - val_accuracy: 0.6714\n","Epoch 40/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.6770 - accuracy: 0.7181 - val_loss: 0.7920 - val_accuracy: 0.6543\n","Epoch 41/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.6497 - accuracy: 0.7289 - val_loss: 0.7493 - val_accuracy: 0.7000\n","Epoch 42/100\n","50/50 [==============================] - 10s 196ms/step - loss: 0.6419 - accuracy: 0.7235 - val_loss: 0.7079 - val_accuracy: 0.6943\n","Epoch 43/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6177 - accuracy: 0.7387 - val_loss: 0.7238 - val_accuracy: 0.6829\n","Epoch 44/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.6294 - accuracy: 0.7343 - val_loss: 0.7580 - val_accuracy: 0.6714\n","Epoch 45/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.6429 - accuracy: 0.7225 - val_loss: 0.7391 - val_accuracy: 0.7171\n","Epoch 46/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.6646 - accuracy: 0.7229 - val_loss: 0.8203 - val_accuracy: 0.6771\n","Epoch 47/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6380 - accuracy: 0.7295 - val_loss: 0.8012 - val_accuracy: 0.7229\n","Epoch 48/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.6619 - accuracy: 0.7311 - val_loss: 0.7038 - val_accuracy: 0.7114\n","Epoch 49/100\n","50/50 [==============================] - 10s 196ms/step - loss: 0.6418 - accuracy: 0.7324 - val_loss: 0.7524 - val_accuracy: 0.6914\n","Epoch 50/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5956 - accuracy: 0.7505 - val_loss: 0.7665 - val_accuracy: 0.6886\n","Epoch 51/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.5989 - accuracy: 0.7457 - val_loss: 0.7636 - val_accuracy: 0.6857\n","Epoch 52/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5852 - accuracy: 0.7400 - val_loss: 0.6935 - val_accuracy: 0.7286\n","Epoch 53/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6203 - accuracy: 0.7492 - val_loss: 0.7536 - val_accuracy: 0.6771\n","Epoch 54/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.5866 - accuracy: 0.7505 - val_loss: 0.7607 - val_accuracy: 0.7171\n","Epoch 55/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6316 - accuracy: 0.7435 - val_loss: 0.7535 - val_accuracy: 0.7114\n","Epoch 56/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5996 - accuracy: 0.7492 - val_loss: 0.7071 - val_accuracy: 0.6914\n","Epoch 57/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5878 - accuracy: 0.7517 - val_loss: 0.7249 - val_accuracy: 0.7171\n","Epoch 58/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6068 - accuracy: 0.7546 - val_loss: 0.7666 - val_accuracy: 0.6657\n","Epoch 59/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6031 - accuracy: 0.7403 - val_loss: 0.7287 - val_accuracy: 0.7086\n","Epoch 60/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6247 - accuracy: 0.7435 - val_loss: 0.7773 - val_accuracy: 0.7029\n","Epoch 61/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.5680 - accuracy: 0.7603 - val_loss: 0.6974 - val_accuracy: 0.7086\n","Epoch 62/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.6315 - accuracy: 0.7413 - val_loss: 0.7138 - val_accuracy: 0.7057\n","Epoch 63/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5406 - accuracy: 0.7768 - val_loss: 0.9065 - val_accuracy: 0.7257\n","Epoch 64/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.5936 - accuracy: 0.7502 - val_loss: 0.9230 - val_accuracy: 0.6743\n","Epoch 65/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.5654 - accuracy: 0.7613 - val_loss: 0.7785 - val_accuracy: 0.7029\n","Epoch 66/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.5653 - accuracy: 0.7606 - val_loss: 0.8299 - val_accuracy: 0.7029\n","Epoch 67/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5733 - accuracy: 0.7619 - val_loss: 0.7618 - val_accuracy: 0.6886\n","Epoch 68/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.5763 - accuracy: 0.7625 - val_loss: 0.7232 - val_accuracy: 0.6829\n","Epoch 69/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.5232 - accuracy: 0.7857 - val_loss: 0.7643 - val_accuracy: 0.6886\n","Epoch 70/100\n","50/50 [==============================] - 10s 196ms/step - loss: 0.5495 - accuracy: 0.7654 - val_loss: 0.7111 - val_accuracy: 0.6886\n","Epoch 71/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5389 - accuracy: 0.7863 - val_loss: 0.7398 - val_accuracy: 0.7171\n","Epoch 72/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.5485 - accuracy: 0.7737 - val_loss: 0.7342 - val_accuracy: 0.7086\n","Epoch 73/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5447 - accuracy: 0.7813 - val_loss: 0.7442 - val_accuracy: 0.7029\n","Epoch 74/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5413 - accuracy: 0.7781 - val_loss: 0.7265 - val_accuracy: 0.7257\n","Epoch 75/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5375 - accuracy: 0.7841 - val_loss: 0.7820 - val_accuracy: 0.7171\n","Epoch 76/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5176 - accuracy: 0.7841 - val_loss: 0.7473 - val_accuracy: 0.7057\n","Epoch 77/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5194 - accuracy: 0.7908 - val_loss: 0.7419 - val_accuracy: 0.7229\n","Epoch 78/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.4890 - accuracy: 0.8051 - val_loss: 0.7928 - val_accuracy: 0.7086\n","Epoch 79/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5336 - accuracy: 0.7816 - val_loss: 0.7503 - val_accuracy: 0.6800\n","Epoch 80/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5283 - accuracy: 0.7800 - val_loss: 0.7588 - val_accuracy: 0.7286\n","Epoch 81/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.5524 - accuracy: 0.7835 - val_loss: 0.7127 - val_accuracy: 0.7114\n","Epoch 82/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.4801 - accuracy: 0.8108 - val_loss: 0.8048 - val_accuracy: 0.7200\n","Epoch 83/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5152 - accuracy: 0.7816 - val_loss: 0.7422 - val_accuracy: 0.7171\n","Epoch 84/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.4925 - accuracy: 0.8019 - val_loss: 0.7627 - val_accuracy: 0.7057\n","Epoch 85/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.4874 - accuracy: 0.7994 - val_loss: 0.7035 - val_accuracy: 0.7143\n","Epoch 86/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.5159 - accuracy: 0.7959 - val_loss: 0.7220 - val_accuracy: 0.7086\n","Epoch 87/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4981 - accuracy: 0.7971 - val_loss: 0.6659 - val_accuracy: 0.7057\n","Epoch 88/100\n","50/50 [==============================] - 10s 196ms/step - loss: 0.5254 - accuracy: 0.7943 - val_loss: 0.7017 - val_accuracy: 0.7429\n","Epoch 89/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.5053 - accuracy: 0.8006 - val_loss: 0.7018 - val_accuracy: 0.7057\n","Epoch 90/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5036 - accuracy: 0.8067 - val_loss: 0.7294 - val_accuracy: 0.7086\n","Epoch 91/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5210 - accuracy: 0.8041 - val_loss: 0.7445 - val_accuracy: 0.7229\n","Epoch 92/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.4904 - accuracy: 0.8035 - val_loss: 0.8537 - val_accuracy: 0.7171\n","Epoch 93/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.4568 - accuracy: 0.8175 - val_loss: 0.7569 - val_accuracy: 0.7114\n","Epoch 94/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4737 - accuracy: 0.8114 - val_loss: 0.7691 - val_accuracy: 0.7029\n","Epoch 95/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.4589 - accuracy: 0.8083 - val_loss: 0.8400 - val_accuracy: 0.7257\n","Epoch 96/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.4419 - accuracy: 0.8124 - val_loss: 0.8306 - val_accuracy: 0.7114\n","Epoch 97/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.4901 - accuracy: 0.8105 - val_loss: 0.8232 - val_accuracy: 0.7000\n","Epoch 98/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.4676 - accuracy: 0.8086 - val_loss: 0.8373 - val_accuracy: 0.7143\n","Epoch 99/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.4891 - accuracy: 0.8076 - val_loss: 0.7450 - val_accuracy: 0.7200\n","Epoch 100/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.4309 - accuracy: 0.8210 - val_loss: 0.9129 - val_accuracy: 0.7171\n","6/6 [==============================] - 1s 179ms/step - loss: 0.9129 - accuracy: 0.7171\n","Test accuracy: 71.71% \n","\n","   \n","Training for fold 2 ... \n","\n","Found 3150 images belonging to 5 classes.\n","Found 350 images belonging to 5 classes.\n","Epoch 1/100\n","50/50 [==============================] - 26s 216ms/step - loss: 4.4795 - accuracy: 0.3486 - val_loss: 1.4557 - val_accuracy: 0.4171\n","Epoch 2/100\n","50/50 [==============================] - 10s 201ms/step - loss: 1.7200 - accuracy: 0.3768 - val_loss: 1.3488 - val_accuracy: 0.3714\n","Epoch 3/100\n","50/50 [==============================] - 10s 201ms/step - loss: 1.4112 - accuracy: 0.4089 - val_loss: 1.2252 - val_accuracy: 0.4571\n","Epoch 4/100\n","50/50 [==============================] - 10s 203ms/step - loss: 1.3140 - accuracy: 0.4429 - val_loss: 1.1957 - val_accuracy: 0.4771\n","Epoch 5/100\n","50/50 [==============================] - 10s 202ms/step - loss: 1.2555 - accuracy: 0.4689 - val_loss: 1.1030 - val_accuracy: 0.5229\n","Epoch 6/100\n","50/50 [==============================] - 10s 204ms/step - loss: 1.1484 - accuracy: 0.5206 - val_loss: 1.0398 - val_accuracy: 0.5914\n","Epoch 7/100\n","50/50 [==============================] - 10s 204ms/step - loss: 1.0960 - accuracy: 0.5352 - val_loss: 0.9752 - val_accuracy: 0.6371\n","Epoch 8/100\n","50/50 [==============================] - 10s 202ms/step - loss: 1.0203 - accuracy: 0.5832 - val_loss: 0.9198 - val_accuracy: 0.6286\n","Epoch 9/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.9692 - accuracy: 0.6092 - val_loss: 0.9005 - val_accuracy: 0.6229\n","Epoch 10/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.9208 - accuracy: 0.6114 - val_loss: 0.8961 - val_accuracy: 0.6429\n","Epoch 11/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.8944 - accuracy: 0.6406 - val_loss: 0.8947 - val_accuracy: 0.6171\n","Epoch 12/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.8512 - accuracy: 0.6530 - val_loss: 0.8484 - val_accuracy: 0.6914\n","Epoch 13/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.8626 - accuracy: 0.6406 - val_loss: 0.8372 - val_accuracy: 0.6886\n","Epoch 14/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.8346 - accuracy: 0.6524 - val_loss: 0.8626 - val_accuracy: 0.6314\n","Epoch 15/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.8340 - accuracy: 0.6413 - val_loss: 0.8519 - val_accuracy: 0.6514\n","Epoch 16/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.7776 - accuracy: 0.6692 - val_loss: 0.7708 - val_accuracy: 0.6943\n","Epoch 17/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.7847 - accuracy: 0.6730 - val_loss: 0.7916 - val_accuracy: 0.6857\n","Epoch 18/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.8014 - accuracy: 0.6505 - val_loss: 0.8030 - val_accuracy: 0.6543\n","Epoch 19/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.7680 - accuracy: 0.6844 - val_loss: 0.8283 - val_accuracy: 0.6486\n","Epoch 20/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.7477 - accuracy: 0.6822 - val_loss: 0.7887 - val_accuracy: 0.6914\n","Epoch 21/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.7647 - accuracy: 0.6778 - val_loss: 0.7941 - val_accuracy: 0.7029\n","Epoch 22/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.7814 - accuracy: 0.6822 - val_loss: 0.8067 - val_accuracy: 0.6914\n","Epoch 23/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.7616 - accuracy: 0.6898 - val_loss: 0.7609 - val_accuracy: 0.7086\n","Epoch 24/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.7442 - accuracy: 0.6952 - val_loss: 0.8273 - val_accuracy: 0.6743\n","Epoch 25/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.7330 - accuracy: 0.6943 - val_loss: 0.7717 - val_accuracy: 0.6800\n","Epoch 26/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.7372 - accuracy: 0.6857 - val_loss: 0.7656 - val_accuracy: 0.7171\n","Epoch 27/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.7063 - accuracy: 0.6975 - val_loss: 0.7126 - val_accuracy: 0.6800\n","Epoch 28/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.6912 - accuracy: 0.7029 - val_loss: 0.7538 - val_accuracy: 0.7114\n","Epoch 29/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.7142 - accuracy: 0.7067 - val_loss: 0.8110 - val_accuracy: 0.6714\n","Epoch 30/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6910 - accuracy: 0.7048 - val_loss: 0.7639 - val_accuracy: 0.7114\n","Epoch 31/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6792 - accuracy: 0.7143 - val_loss: 0.7299 - val_accuracy: 0.7143\n","Epoch 32/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.6800 - accuracy: 0.7102 - val_loss: 0.7303 - val_accuracy: 0.7114\n","Epoch 33/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.7037 - accuracy: 0.7070 - val_loss: 0.7410 - val_accuracy: 0.6971\n","Epoch 34/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6479 - accuracy: 0.7244 - val_loss: 0.7162 - val_accuracy: 0.7200\n","Epoch 35/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6661 - accuracy: 0.7194 - val_loss: 0.7916 - val_accuracy: 0.6886\n","Epoch 36/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6664 - accuracy: 0.7127 - val_loss: 0.7200 - val_accuracy: 0.7314\n","Epoch 37/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6768 - accuracy: 0.7152 - val_loss: 0.6834 - val_accuracy: 0.7286\n","Epoch 38/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6640 - accuracy: 0.7286 - val_loss: 0.7497 - val_accuracy: 0.6800\n","Epoch 39/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6637 - accuracy: 0.7175 - val_loss: 0.7299 - val_accuracy: 0.7286\n","Epoch 40/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6426 - accuracy: 0.7241 - val_loss: 0.7553 - val_accuracy: 0.7143\n","Epoch 41/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6472 - accuracy: 0.7305 - val_loss: 0.7584 - val_accuracy: 0.6943\n","Epoch 42/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.6440 - accuracy: 0.7311 - val_loss: 0.7531 - val_accuracy: 0.7200\n","Epoch 43/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6447 - accuracy: 0.7317 - val_loss: 0.7371 - val_accuracy: 0.7400\n","Epoch 44/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.6155 - accuracy: 0.7413 - val_loss: 0.7254 - val_accuracy: 0.7200\n","Epoch 45/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.6046 - accuracy: 0.7460 - val_loss: 0.7335 - val_accuracy: 0.7171\n","Epoch 46/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.5967 - accuracy: 0.7476 - val_loss: 0.7591 - val_accuracy: 0.7286\n","Epoch 47/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.6050 - accuracy: 0.7470 - val_loss: 0.6920 - val_accuracy: 0.7257\n","Epoch 48/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.5787 - accuracy: 0.7590 - val_loss: 0.7306 - val_accuracy: 0.7343\n","Epoch 49/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6241 - accuracy: 0.7371 - val_loss: 0.7335 - val_accuracy: 0.7371\n","Epoch 50/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.5878 - accuracy: 0.7521 - val_loss: 0.7705 - val_accuracy: 0.7314\n","Epoch 51/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5975 - accuracy: 0.7610 - val_loss: 0.7457 - val_accuracy: 0.7000\n","Epoch 52/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5922 - accuracy: 0.7581 - val_loss: 0.7436 - val_accuracy: 0.7200\n","Epoch 53/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.6044 - accuracy: 0.7562 - val_loss: 0.7274 - val_accuracy: 0.7286\n","Epoch 54/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.5602 - accuracy: 0.7679 - val_loss: 0.7423 - val_accuracy: 0.7400\n","Epoch 55/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.5664 - accuracy: 0.7711 - val_loss: 0.7779 - val_accuracy: 0.7371\n","Epoch 56/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.6033 - accuracy: 0.7594 - val_loss: 0.7540 - val_accuracy: 0.7371\n","Epoch 57/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.5707 - accuracy: 0.7743 - val_loss: 0.7858 - val_accuracy: 0.7029\n","Epoch 58/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5607 - accuracy: 0.7686 - val_loss: 0.7311 - val_accuracy: 0.7457\n","Epoch 59/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.5476 - accuracy: 0.7714 - val_loss: 0.7389 - val_accuracy: 0.7400\n","Epoch 60/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5365 - accuracy: 0.7803 - val_loss: 0.7420 - val_accuracy: 0.7143\n","Epoch 61/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.5373 - accuracy: 0.7810 - val_loss: 0.7620 - val_accuracy: 0.7114\n","Epoch 62/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5428 - accuracy: 0.7813 - val_loss: 0.7413 - val_accuracy: 0.7457\n","Epoch 63/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5652 - accuracy: 0.7771 - val_loss: 0.6856 - val_accuracy: 0.7314\n","Epoch 64/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.5301 - accuracy: 0.7803 - val_loss: 0.7450 - val_accuracy: 0.7400\n","Epoch 65/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.5772 - accuracy: 0.7648 - val_loss: 0.7831 - val_accuracy: 0.7114\n","Epoch 66/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.5664 - accuracy: 0.7654 - val_loss: 0.7566 - val_accuracy: 0.7257\n","Epoch 67/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.5460 - accuracy: 0.7746 - val_loss: 0.9269 - val_accuracy: 0.7171\n","Epoch 68/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.5496 - accuracy: 0.7851 - val_loss: 0.7690 - val_accuracy: 0.7057\n","Epoch 69/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5478 - accuracy: 0.7781 - val_loss: 0.8627 - val_accuracy: 0.7343\n","Epoch 70/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.5664 - accuracy: 0.7794 - val_loss: 0.7603 - val_accuracy: 0.7571\n","Epoch 71/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.5256 - accuracy: 0.7854 - val_loss: 0.7792 - val_accuracy: 0.7571\n","Epoch 72/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5112 - accuracy: 0.7892 - val_loss: 0.7293 - val_accuracy: 0.7600\n","Epoch 73/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.4972 - accuracy: 0.8016 - val_loss: 0.7432 - val_accuracy: 0.7486\n","Epoch 74/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.5092 - accuracy: 0.7921 - val_loss: 0.7501 - val_accuracy: 0.7514\n","Epoch 75/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.5041 - accuracy: 0.7997 - val_loss: 0.8768 - val_accuracy: 0.7257\n","Epoch 76/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.4886 - accuracy: 0.7971 - val_loss: 0.8348 - val_accuracy: 0.7600\n","Epoch 77/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.4695 - accuracy: 0.8070 - val_loss: 0.8882 - val_accuracy: 0.7429\n","Epoch 78/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.4897 - accuracy: 0.8041 - val_loss: 0.7441 - val_accuracy: 0.7571\n","Epoch 79/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.4980 - accuracy: 0.7968 - val_loss: 0.7414 - val_accuracy: 0.7686\n","Epoch 80/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.5038 - accuracy: 0.8041 - val_loss: 0.8160 - val_accuracy: 0.7429\n","Epoch 81/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.4977 - accuracy: 0.7933 - val_loss: 0.7585 - val_accuracy: 0.7200\n","Epoch 82/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5076 - accuracy: 0.8016 - val_loss: 0.7367 - val_accuracy: 0.7600\n","Epoch 83/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.4959 - accuracy: 0.8038 - val_loss: 0.7546 - val_accuracy: 0.7514\n","Epoch 84/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4612 - accuracy: 0.8117 - val_loss: 0.8241 - val_accuracy: 0.7286\n","Epoch 85/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.4828 - accuracy: 0.8117 - val_loss: 0.8764 - val_accuracy: 0.7543\n","Epoch 86/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.5100 - accuracy: 0.8032 - val_loss: 0.8649 - val_accuracy: 0.7314\n","Epoch 87/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.4799 - accuracy: 0.8041 - val_loss: 0.8661 - val_accuracy: 0.7600\n","Epoch 88/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.5050 - accuracy: 0.8070 - val_loss: 0.8654 - val_accuracy: 0.7457\n","Epoch 89/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.4396 - accuracy: 0.8257 - val_loss: 0.7432 - val_accuracy: 0.7714\n","Epoch 90/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.4465 - accuracy: 0.8184 - val_loss: 0.7845 - val_accuracy: 0.7714\n","Epoch 91/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.4383 - accuracy: 0.8229 - val_loss: 0.8338 - val_accuracy: 0.7514\n","Epoch 92/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.4548 - accuracy: 0.8216 - val_loss: 0.8838 - val_accuracy: 0.7571\n","Epoch 93/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.4746 - accuracy: 0.8219 - val_loss: 0.7224 - val_accuracy: 0.7657\n","Epoch 94/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.4494 - accuracy: 0.8200 - val_loss: 0.7797 - val_accuracy: 0.7514\n","Epoch 95/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.4331 - accuracy: 0.8248 - val_loss: 0.7844 - val_accuracy: 0.7571\n","Epoch 96/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.4223 - accuracy: 0.8397 - val_loss: 0.8720 - val_accuracy: 0.7457\n","Epoch 97/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.4223 - accuracy: 0.8289 - val_loss: 0.8871 - val_accuracy: 0.7457\n","Epoch 98/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4524 - accuracy: 0.8251 - val_loss: 0.8731 - val_accuracy: 0.7429\n","Epoch 99/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.4242 - accuracy: 0.8302 - val_loss: 0.8886 - val_accuracy: 0.7514\n","Epoch 100/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.4356 - accuracy: 0.8283 - val_loss: 0.8926 - val_accuracy: 0.7286\n","6/6 [==============================] - 1s 174ms/step - loss: 0.8926 - accuracy: 0.7286\n","Test accuracy: 72.86% \n","\n","   \n","Training for fold 3 ... \n","\n","Found 3150 images belonging to 5 classes.\n","Found 350 images belonging to 5 classes.\n","Epoch 1/100\n","50/50 [==============================] - 26s 212ms/step - loss: 4.3955 - accuracy: 0.3422 - val_loss: 1.3715 - val_accuracy: 0.3914\n","Epoch 2/100\n","50/50 [==============================] - 10s 202ms/step - loss: 1.6293 - accuracy: 0.3968 - val_loss: 1.2448 - val_accuracy: 0.4629\n","Epoch 3/100\n","50/50 [==============================] - 10s 204ms/step - loss: 1.4221 - accuracy: 0.4260 - val_loss: 1.1984 - val_accuracy: 0.4886\n","Epoch 4/100\n","50/50 [==============================] - 10s 203ms/step - loss: 1.3229 - accuracy: 0.4410 - val_loss: 1.1803 - val_accuracy: 0.4743\n","Epoch 5/100\n","50/50 [==============================] - 10s 206ms/step - loss: 1.2363 - accuracy: 0.4813 - val_loss: 1.0879 - val_accuracy: 0.5457\n","Epoch 6/100\n","50/50 [==============================] - 10s 202ms/step - loss: 1.1498 - accuracy: 0.5143 - val_loss: 1.0098 - val_accuracy: 0.6029\n","Epoch 7/100\n","50/50 [==============================] - 10s 204ms/step - loss: 1.0499 - accuracy: 0.5781 - val_loss: 0.9881 - val_accuracy: 0.6114\n","Epoch 8/100\n","50/50 [==============================] - 10s 204ms/step - loss: 1.0227 - accuracy: 0.5879 - val_loss: 0.9571 - val_accuracy: 0.6714\n","Epoch 9/100\n","50/50 [==============================] - 10s 208ms/step - loss: 0.9695 - accuracy: 0.6124 - val_loss: 0.8583 - val_accuracy: 0.6229\n","Epoch 10/100\n","50/50 [==============================] - 10s 207ms/step - loss: 0.9222 - accuracy: 0.6184 - val_loss: 0.8481 - val_accuracy: 0.6343\n","Epoch 11/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.9198 - accuracy: 0.6241 - val_loss: 0.8835 - val_accuracy: 0.6257\n","Epoch 12/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.8676 - accuracy: 0.6470 - val_loss: 0.9324 - val_accuracy: 0.6000\n","Epoch 13/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.8534 - accuracy: 0.6489 - val_loss: 0.9071 - val_accuracy: 0.6371\n","Epoch 14/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.8577 - accuracy: 0.6438 - val_loss: 0.8793 - val_accuracy: 0.6629\n","Epoch 15/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.8324 - accuracy: 0.6651 - val_loss: 0.8592 - val_accuracy: 0.6543\n","Epoch 16/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.8200 - accuracy: 0.6603 - val_loss: 0.8705 - val_accuracy: 0.6457\n","Epoch 17/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.8039 - accuracy: 0.6638 - val_loss: 0.8583 - val_accuracy: 0.6429\n","Epoch 18/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.7727 - accuracy: 0.6644 - val_loss: 0.8666 - val_accuracy: 0.6543\n","Epoch 19/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.7892 - accuracy: 0.6794 - val_loss: 0.8525 - val_accuracy: 0.6543\n","Epoch 20/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.7687 - accuracy: 0.6673 - val_loss: 0.9399 - val_accuracy: 0.6114\n","Epoch 21/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.7613 - accuracy: 0.6717 - val_loss: 0.7920 - val_accuracy: 0.6914\n","Epoch 22/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.7445 - accuracy: 0.6851 - val_loss: 0.7976 - val_accuracy: 0.7000\n","Epoch 23/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.7378 - accuracy: 0.6917 - val_loss: 0.8276 - val_accuracy: 0.6743\n","Epoch 24/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.7647 - accuracy: 0.6835 - val_loss: 0.7939 - val_accuracy: 0.7114\n","Epoch 25/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.7435 - accuracy: 0.7019 - val_loss: 0.7583 - val_accuracy: 0.7000\n","Epoch 26/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.7049 - accuracy: 0.7054 - val_loss: 0.8559 - val_accuracy: 0.6743\n","Epoch 27/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.7147 - accuracy: 0.6956 - val_loss: 0.8327 - val_accuracy: 0.6886\n","Epoch 28/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6947 - accuracy: 0.7057 - val_loss: 0.8700 - val_accuracy: 0.6600\n","Epoch 29/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.7082 - accuracy: 0.7044 - val_loss: 1.0006 - val_accuracy: 0.6629\n","Epoch 30/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.7247 - accuracy: 0.7016 - val_loss: 0.7575 - val_accuracy: 0.7057\n","Epoch 31/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.6778 - accuracy: 0.7095 - val_loss: 0.8414 - val_accuracy: 0.6943\n","Epoch 32/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6759 - accuracy: 0.7102 - val_loss: 0.8989 - val_accuracy: 0.6543\n","Epoch 33/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6627 - accuracy: 0.7178 - val_loss: 0.8404 - val_accuracy: 0.6800\n","Epoch 34/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6811 - accuracy: 0.7178 - val_loss: 0.8763 - val_accuracy: 0.6914\n","Epoch 35/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.7534 - accuracy: 0.6962 - val_loss: 0.7246 - val_accuracy: 0.7143\n","Epoch 36/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.6793 - accuracy: 0.7235 - val_loss: 0.7517 - val_accuracy: 0.6771\n","Epoch 37/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.6526 - accuracy: 0.7190 - val_loss: 0.7954 - val_accuracy: 0.7086\n","Epoch 38/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.6527 - accuracy: 0.7283 - val_loss: 0.9563 - val_accuracy: 0.7029\n","Epoch 39/100\n","50/50 [==============================] - 10s 207ms/step - loss: 0.6520 - accuracy: 0.7305 - val_loss: 0.8503 - val_accuracy: 0.6829\n","Epoch 40/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6598 - accuracy: 0.7397 - val_loss: 0.8225 - val_accuracy: 0.6829\n","Epoch 41/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.6478 - accuracy: 0.7337 - val_loss: 0.8757 - val_accuracy: 0.6971\n","Epoch 42/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.6261 - accuracy: 0.7333 - val_loss: 0.8576 - val_accuracy: 0.7057\n","Epoch 43/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.6429 - accuracy: 0.7359 - val_loss: 0.7628 - val_accuracy: 0.7200\n","Epoch 44/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.6404 - accuracy: 0.7346 - val_loss: 0.9097 - val_accuracy: 0.6743\n","Epoch 45/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.6302 - accuracy: 0.7295 - val_loss: 0.7751 - val_accuracy: 0.7457\n","Epoch 46/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.6009 - accuracy: 0.7473 - val_loss: 0.8205 - val_accuracy: 0.7086\n","Epoch 47/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6108 - accuracy: 0.7371 - val_loss: 0.9132 - val_accuracy: 0.7314\n","Epoch 48/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.6176 - accuracy: 0.7406 - val_loss: 0.9304 - val_accuracy: 0.7229\n","Epoch 49/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.6326 - accuracy: 0.7387 - val_loss: 0.7781 - val_accuracy: 0.6771\n","Epoch 50/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6170 - accuracy: 0.7403 - val_loss: 0.7627 - val_accuracy: 0.6943\n","Epoch 51/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.6191 - accuracy: 0.7438 - val_loss: 0.9473 - val_accuracy: 0.7057\n","Epoch 52/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.6340 - accuracy: 0.7356 - val_loss: 0.7565 - val_accuracy: 0.7457\n","Epoch 53/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.6070 - accuracy: 0.7419 - val_loss: 0.7924 - val_accuracy: 0.7086\n","Epoch 54/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.5940 - accuracy: 0.7616 - val_loss: 0.7808 - val_accuracy: 0.7229\n","Epoch 55/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.5937 - accuracy: 0.7457 - val_loss: 0.8451 - val_accuracy: 0.6886\n","Epoch 56/100\n","50/50 [==============================] - 10s 197ms/step - loss: 0.5828 - accuracy: 0.7444 - val_loss: 0.8940 - val_accuracy: 0.6971\n","Epoch 57/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.5475 - accuracy: 0.7702 - val_loss: 0.9463 - val_accuracy: 0.7057\n","Epoch 58/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5879 - accuracy: 0.7638 - val_loss: 0.7948 - val_accuracy: 0.7000\n","Epoch 59/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5751 - accuracy: 0.7676 - val_loss: 0.8654 - val_accuracy: 0.7429\n","Epoch 60/100\n","50/50 [==============================] - 10s 208ms/step - loss: 0.5739 - accuracy: 0.7635 - val_loss: 0.8536 - val_accuracy: 0.7429\n","Epoch 61/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.6003 - accuracy: 0.7575 - val_loss: 0.8362 - val_accuracy: 0.7229\n","Epoch 62/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.5439 - accuracy: 0.7743 - val_loss: 0.8878 - val_accuracy: 0.6771\n","Epoch 63/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.5884 - accuracy: 0.7562 - val_loss: 0.8010 - val_accuracy: 0.6771\n","Epoch 64/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5549 - accuracy: 0.7730 - val_loss: 0.9324 - val_accuracy: 0.7057\n","Epoch 65/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.5604 - accuracy: 0.7673 - val_loss: 0.8448 - val_accuracy: 0.6971\n","Epoch 66/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5603 - accuracy: 0.7724 - val_loss: 0.8485 - val_accuracy: 0.6914\n","Epoch 67/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.5583 - accuracy: 0.7597 - val_loss: 0.9083 - val_accuracy: 0.6714\n","Epoch 68/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5391 - accuracy: 0.7775 - val_loss: 0.9559 - val_accuracy: 0.6771\n","Epoch 69/100\n","50/50 [==============================] - 10s 198ms/step - loss: 0.5583 - accuracy: 0.7698 - val_loss: 0.8145 - val_accuracy: 0.7057\n","Epoch 70/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5282 - accuracy: 0.7800 - val_loss: 0.8349 - val_accuracy: 0.6800\n","Epoch 71/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.5323 - accuracy: 0.7794 - val_loss: 0.8138 - val_accuracy: 0.7200\n","Epoch 72/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.5177 - accuracy: 0.7838 - val_loss: 0.7643 - val_accuracy: 0.7200\n","Epoch 73/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.5140 - accuracy: 0.7841 - val_loss: 0.7929 - val_accuracy: 0.7314\n","Epoch 74/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.4740 - accuracy: 0.8038 - val_loss: 0.8579 - val_accuracy: 0.7200\n","Epoch 75/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5040 - accuracy: 0.7886 - val_loss: 0.9643 - val_accuracy: 0.6886\n","Epoch 76/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5422 - accuracy: 0.7825 - val_loss: 0.7996 - val_accuracy: 0.6971\n","Epoch 77/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.5013 - accuracy: 0.7879 - val_loss: 0.7976 - val_accuracy: 0.7229\n","Epoch 78/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.4904 - accuracy: 0.7987 - val_loss: 0.7810 - val_accuracy: 0.7171\n","Epoch 79/100\n","50/50 [==============================] - 10s 203ms/step - loss: 0.5183 - accuracy: 0.7921 - val_loss: 0.9430 - val_accuracy: 0.6686\n","Epoch 80/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.5074 - accuracy: 0.7927 - val_loss: 0.8354 - val_accuracy: 0.7143\n","Epoch 81/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.5187 - accuracy: 0.7886 - val_loss: 0.9319 - val_accuracy: 0.7286\n","Epoch 82/100\n","50/50 [==============================] - 10s 200ms/step - loss: 0.5338 - accuracy: 0.7759 - val_loss: 0.9027 - val_accuracy: 0.6943\n","Epoch 83/100\n","50/50 [==============================] - 10s 207ms/step - loss: 0.5048 - accuracy: 0.7895 - val_loss: 0.8858 - val_accuracy: 0.7086\n","Epoch 84/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4980 - accuracy: 0.8013 - val_loss: 0.8359 - val_accuracy: 0.6943\n","Epoch 85/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.5161 - accuracy: 0.7917 - val_loss: 0.8987 - val_accuracy: 0.7286\n","Epoch 86/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4816 - accuracy: 0.7962 - val_loss: 1.1144 - val_accuracy: 0.7029\n","Epoch 87/100\n","50/50 [==============================] - 10s 199ms/step - loss: 0.4783 - accuracy: 0.8032 - val_loss: 1.0607 - val_accuracy: 0.7057\n","Epoch 88/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4972 - accuracy: 0.8067 - val_loss: 0.8966 - val_accuracy: 0.6971\n","Epoch 89/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5192 - accuracy: 0.7940 - val_loss: 0.8891 - val_accuracy: 0.7114\n","Epoch 90/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.4944 - accuracy: 0.8041 - val_loss: 0.9339 - val_accuracy: 0.7171\n","Epoch 91/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.5082 - accuracy: 0.7937 - val_loss: 0.9378 - val_accuracy: 0.7000\n","Epoch 92/100\n","50/50 [==============================] - 10s 204ms/step - loss: 0.4777 - accuracy: 0.8067 - val_loss: 1.0933 - val_accuracy: 0.7086\n","Epoch 93/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.4592 - accuracy: 0.8156 - val_loss: 0.7992 - val_accuracy: 0.7400\n","Epoch 94/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4570 - accuracy: 0.8114 - val_loss: 0.8488 - val_accuracy: 0.7086\n","Epoch 95/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4653 - accuracy: 0.8197 - val_loss: 0.7788 - val_accuracy: 0.7514\n","Epoch 96/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.4491 - accuracy: 0.8159 - val_loss: 0.8092 - val_accuracy: 0.7114\n","Epoch 97/100\n","50/50 [==============================] - 10s 205ms/step - loss: 0.4717 - accuracy: 0.8130 - val_loss: 0.9760 - val_accuracy: 0.7171\n","Epoch 98/100\n","50/50 [==============================] - 10s 206ms/step - loss: 0.4526 - accuracy: 0.8206 - val_loss: 0.8470 - val_accuracy: 0.7171\n","Epoch 99/100\n","50/50 [==============================] - 10s 202ms/step - loss: 0.4323 - accuracy: 0.8225 - val_loss: 0.9346 - val_accuracy: 0.7229\n","Epoch 100/100\n","50/50 [==============================] - 10s 201ms/step - loss: 0.4958 - accuracy: 0.8127 - val_loss: 1.0111 - val_accuracy: 0.6857\n","6/6 [==============================] - 1s 173ms/step - loss: 1.0111 - accuracy: 0.6857\n","Test accuracy: 68.57% \n","\n"]}]}]}